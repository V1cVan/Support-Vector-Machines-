
% ======================== 1.2.1 ==========================================

%% Parameter sweep of LS-SVM with RBF kernel 
clc, clear, close all 
X = ( -3:0.01:3)';
Y = sinc (X) + 0.1.* randn ( length (X), 1); % sinc function with white noise 

Xtrain = X (1:2: end);
Ytrain = Y (1:2: end);
Xtest = X (2:2: end);
Ytest = Y (2:2: end);

gammas = [10 10^3 10^6]; 
sigma2s = [0.01, 1, 100]; 

mse_list = []; 
type = 'function estimation';
kernel = 'RBF_kernel';
for gam = gammas
    for sig2 = sigma2s 
        model = {Xtrain,Ytrain,type,gam,sig2,kernel}; 
        [alpha,b] = trainlssvm(model);

        % Predict on the test data 
        Yhat = simlssvm(model,{alpha,b},Xtest);
        RMSE = sqrt(mean((Ytest - Yhat).^2));  % Root Mean Squared Error
        mse_list = [mse_list; RMSE];
        disp(sprintf("-- Gamma = %.0f, Sigma = %.2f --, Error = %.2f", gam, sig2, RMSE))
        
        % Plot the LS-SVM result 
        plotlssvm(model,{alpha,b});
        fig = gcf;
        hold on; 
        plot(min(X):.1:max(X),sinc(min(X):.1:max(X)),'b--');
        grid on
        figname = sprintf('../figures/1_2/rbf_reg_sig2_%.2f_gam_%.2f.pdf', sig2, gam);
        saveas(fig, figname)        
    end   
end 


%% Algorithmic tuning of LS-SVM with RBF kernel 
clc, clear, close all 
X = ( -3:0.01:3)';
Y = sinc (X) + 0.1.* randn ( length (X), 1); % sinc function with white noise 

Xtrain = X (1:2: end);
Ytrain = Y (1:2: end);
Xtest = X (2:2: end);
Ytest = Y (2:2: end);

type = 'function estimation';
kernel = 'RBF_kernel';

% ----- GRID SEARCH ------

% Tune for optimal parameters (GRID SEARCH) 
search_method = 'gridsearch'; 
model = {Xtrain,Ytrain,type,[],[],kernel}; 
[gam_grid, sig2_grid] = tunelssvm(model, search_method, 'crossvalidatelssvm', {10,'mse'});
tuned_model_grid = {Xtrain,Ytrain,type,gam_grid,sig2_grid,kernel}; 
[alpha_grid,b_grid] = trainlssvm(tuned_model_grid);

% Predict on the test data 
Yhat = simlssvm(tuned_model_grid,{alpha_grid,b_grid},Xtest);
RMSE_grid = sqrt(mean((Ytest - Yhat).^2));

% ----- SIMPLEX ------

% Tune for optimal parameters (SIMPLEX) 
search_method = 'simplex'; 
model = {Xtrain,Ytrain,type,[],[],kernel}; 
[gam_simplex, sig2_simplex] = tunelssvm(model, search_method, 'crossvalidatelssvm', {10,'mse'});
tuned_model_simplex = {Xtrain,Ytrain,type,gam_simplex,sig2_simplex,kernel}; 
[alpha_simplex,b_simplex] = trainlssvm(tuned_model_simplex);

% Predict on the test data 
Yhat = simlssvm(tuned_model_simplex,{alpha_simplex,b_simplex},Xtest);
RMSE_simplex = sqrt(mean((Ytest - Yhat).^2));

figure()
% Plot simplex 
plotlssvm(tuned_model_simplex,{alpha_simplex,b_simplex});
hold on; 
plot(min(X):.1:max(X),sinc(min(X):.1:max(X)),'b--');
fig = gcf;
grid on
legend('Simplex tuned SV Regression','Datapoints', 'Sinc Function')
figname = '../figures/1_2/rbf_tuning_results_simp.pdf';
saveas(fig, figname) 

figure()
% Plot gridsearch 
plotlssvm(tuned_model_grid,{alpha_grid,b_grid});
hold on; 
plot(min(X):.1:max(X),sinc(min(X):.1:max(X)),'b--');
fig = gcf;
grid on
legend('Gridsearch tuned SV Regression','Datapoints', 'Sinc Function')
figname = '../figures/1_2/rbf_tuning_results_grid.pdf';
saveas(fig, figname)        

disp(sprintf("--\nSearch metod: SIMPLEX\n  Gamma = %.2f, Sigma = %.2f --, Error = %.2f", gam_simplex, sig2_simplex, RMSE_simplex))
disp(sprintf("--\nSearch metod: Gridsearch\n  Gamma = %.0f, Sigma = %.2f --, Error = %.2f", gam_grid, sig2_grid, RMSE_grid))



% ======================== 1.2.2 ==========================================

%% Application of the Bayesian Framework 
clc, close all 

%{
In addition to the approach outlined above, the Bayesian framework can also be used to tune
and to analyze the LS-SVM regressor. The basic result from the Bayesian framework for the
LS-SVM is the derivation of the probability that the data points are generated by the given
model. This is called the posterior probability. This probability criterion is expressed as a
number. There are 3 variants: the posterior with respect to the model parameters alpha
and b, the posterior with respect to the regularization constant gam and the posterior with
respect to the choice of the kernel and its parameter sig2. The cost (negative logarithm of
the posteriors) is computed by the function call
%}


sig2 = 0.4;
gam = 10;
crit_L1 = bay_lssvm ({ Xtrain , Ytrain , 'f', gam , sig2 }, 1);
crit_L2 = bay_lssvm ({ Xtrain , Ytrain , 'f', gam , sig2 }, 2);
crit_L3 = bay_lssvm ({ Xtrain , Ytrain , 'f', gam , sig2 }, 3);
% First level: In the first level one optimizes the support values ?’s and the bias b.
[~, alpha ,b] = bay_optimize ({ Xtrain , Ytrain , 'f', gam , sig2 }, 1);
% Second level: In the second level one optimizes the regularization parameter gam.
[~, gam] = bay_optimize ({ Xtrain , Ytrain , 'f', gam , sig2 }, 2);
% Third level: In the third level one optimizes the kernel parameter. In the case of the
% common ’RBF_kernel’ the kernel parameter is the bandwidth sig2.
[~, sig2 ] = bay_optimize ({ Xtrain , Ytrain , 'f', gam , sig2 }, 3);

% For regression, the error bars can be computed using Bayesian inference using
sig2e = bay_errorbar ({ Xtrain , Ytrain , 'f', gam , sig2 }, 'figure');
fig = gcf;
grid on 
legend('Sinc function','Upper conf. interval', 'Lower conf. interval', 'Datapoints')
figname = '../figures/1_2/bayesian_regression.pdf';
saveas(fig, figname)

% ======================== 1.3 ==========================================

%% Automatic Relevance determination 
clc, close all

%{
In addition to parameter tuning, the Bayesian framework can also be used to select the
most relevant inputs by Automatic Relevance Determination (ARD). The following proce-
dure uses this criterion for backward selection for a three dimensional input selection task,
constructed as (use tuned gam and sig2 parameter values):

For a given problem, one can determine the most relevant inputs for the LS-SVM within the
Bayesian evidence framework. To do so, one assigns a different weighting parameter to each
dimension in the kernel and optimizes this using the third level of inference. According to the
used kernel, one can remove inputs based on the larger or smaller kernel parameters. This routine
only works with the ’RBF_kernel’ with a sig2 per input. In each step, the input with the largest
optimal sig2 is removed (backward selection). For every step, the generalization performance is
approximated by the cost associated with the third level of Bayesian inference.
The ARD is based on backward selection of the inputs based on the sig2s corresponding in
each step with a minimal cost criterion. Minimizing this criterion can be done by ’continuous’ or
by ’discrete’. The former uses in each step continuous varying kernel parameter optimization,
the latter decides which one to remove in each step by binary variables for each component (this
can only be applied for rather low dimensional inputs as the number of possible combinations
grows exponentially with the number of inputs). If working with the ’RBF_kernel’, the kernel
parameter is rescaled appropriately after removing an input variable.
The computation of the Bayesian cost criterion can be based on the singular value decomposition
’svd’ of the full kernel matrix or by an approximation of these eigenvalues and vectors by
the ’eigs’ or ’eign’ approximation based on ’nb’ data points.

%}

X = 6.* rand (100 , 3) - 3;
Y = sinc (X(: ,1)) + 0.1.* randn (100 ,1) ;

sig2 = 0.4;
gam = 10;
crit_L1 = bay_lssvm ({ X , Y , 'f', gam , sig2 }, 1);
crit_L2 = bay_lssvm ({ X , Y , 'f', gam , sig2 }, 2);
crit_L3 = bay_lssvm ({ X , Y , 'f', gam , sig2 }, 3);
[~, alpha ,b] = bay_optimize ({ X , Y , 'f', gam , sig2 }, 1);
[~, gam] = bay_optimize ({ X , Y , 'f', gam , sig2 }, 2);
[~, sig2 ] = bay_optimize ({ X , Y , 'f', gam , sig2 }, 3);

model = {X, Y, 'f', gam , sig2 };
[ selected , ranking ] = bay_lssvmARD (model);

figure() 
sig2e = bay_errorbar ({ X(:,selected) , Y , 'f', gam , sig2 }, 'figure');
hold on 
plot(X(:,2:3),Y, '.', 'markersize', 20)
grid on 
fig=gcf
legend('Bayesian regression','Upper 95% conf. bound','Lower 95% conf. bound','Input 1','Input 2','Input 3')
figname = '../figures/1_3/bayesian_regression.pdf';
saveas(fig, figname)

% ======================== 1.4 ==========================================

%% Robust regression 
clc
clear 
close all 
%{
Robust tuning of the tuning parameters is performed by rcrossvalildatelssvm. Also notice
that the preferred loss function is the L1 (mae). The weighting function in the cost function is
chosen to be the Huber weights. Other possibilities, included in the toolbox, are logistic weights,
myriad weights and Hampel weights.

See section in the PDF on robust regresison for differences between: 
    Huber
    Hampel 
    Logisitic
    Myriad
%} 

% Create training data 
X = ( -6:0.2:6)';
Y = sinc (X) + 0.1.* rand ( size (X));

out = [15 17 19];
Y( out) = 0.7+0.3* rand ( size ( out));
out = [41 44 46];
Y( out) = 1.5+0.2* rand ( size ( out));

% Standard regression 
model = initlssvm (X, Y, 'f', [], [], 'RBF_kernel');
costFun = 'crossvalidatelssvm';
model = tunelssvm (model , 'simplex', costFun , {10 , 'mse';});
figure() 
plotlssvm ( model );
grid on 
fig = gcf;
figname = '../figures/1_4/standard_mse.pdf';
saveas(fig, figname)

% Robust regression with wHuber and MAE cost function 
model = initlssvm (X, Y, 'f', [], [], 'RBF_kernel');
costFun = 'rcrossvalidatelssvm';
wFun = 'whuber';
model = tunelssvm (model , 'simplex', costFun , {10 , 'mae';}, wFun );
model = robustlssvm ( model );
figure() 
plotlssvm ( model );
grid on 
fig = gcf;
figname = '../figures/1_4/robust_mae_whuber.pdf';
saveas(fig, figname)


% Robust regression with 'whampel' and MAE cost function 
model = initlssvm (X, Y, 'f', [], [], 'RBF_kernel');
costFun = 'rcrossvalidatelssvm';
wFun = 'whampel';
model = tunelssvm (model , 'simplex', costFun , {10 , 'mae';}, wFun );
model = robustlssvm ( model );
figure() 
plotlssvm ( model );
grid on 
fig = gcf;
figname = '../figures/1_4/robust_mae_whampel.pdf';
saveas(fig, figname)

% Robust regression with 'wlogistic' and MAE cost function 
model = initlssvm (X, Y, 'f', [], [], 'RBF_kernel');
costFun = 'rcrossvalidatelssvm';
wFun = 'wlogistic';
model = tunelssvm (model , 'simplex', costFun , {10 , 'mae';}, wFun );
model = robustlssvm ( model );
figure() 
plotlssvm ( model );
grid on 
fig = gcf;
figname = '../figures/1_4/robust_mae_wlogistic.pdf';
saveas(fig, figname)

% Robust regression with 'wmyriad' and MAE cost function 
model = initlssvm (X, Y, 'f', [], [], 'RBF_kernel');
costFun = 'rcrossvalidatelssvm';
wFun = 'wmyriad';
model = tunelssvm (model , 'simplex', costFun , {10 , 'mae';}, wFun );
model = robustlssvm ( model );
figure() 
plotlssvm ( model );
grid on 
fig = gcf;
figname = '../figures/1_4/robust_mae_wmyriad.pdf';
saveas(fig, figname)


% ======================== 2.2 ==========================================

%% Logmap data set 
clc 
clear
close all 
load logmap.mat

order = 10;
X = windowize (Z, 1:( order + 1));
Y = X(:, end);
X = X(:, 1: order );

gam = 10;
sig2 = 10;
[alpha , b] = trainlssvm ({X, Y, 'f', gam , sig2 });
% Predict the next points 
Xs = Z(end - order +1: end , 1);
nb = 50;
prediction = predict ({X, Y, 'f', gam , sig2 }, Xs , nb);
figure ;
hold on;
plot (Ztest , 'k');
plot ( prediction , 'r');
hold off;
legend('Test set', 'Prediction')
grid on 


% --- optimise parameters: 'gam, sig2, order' ---- 
order_list = [1 3 5 10 20 30 40 50 60 70 80 90 100];
n = length(order_list);

gamlist = zeros(1,n);
sig2list = zeros(1,n);

RMSE_list = zeros(1,n);
MAE_list = zeros(1,n);

for order_index = 1:n
    order = order_list(order_index);
    
    % Prepare the training data
    X = windowize(Z, 1:(order + 1));    
    Y = X(:, end);
    X = X(:, 1:order);
    
    % Tune hyperparameters 
    model = { X , Y , 'f', [], [],'RBF_kernel'};
    algorithm = 'simplex';
    [gam , sig2, cost] = tunelssvm(model, algorithm, 'crossvalidatelssvm',{10, 'mse'});
    
    gamlist(order_index) = gam;
    sig2list(order_index) = sig2;
    
    [alpha, b] = trainlssvm({X, Y, 'f', gam, sig2,'RBF_kernel'});
    
    % Prediction 
    Xs = Z(end - order + 1:end , 1);
    nb = 50;
    prediction = predict({X, Y, 'f', gam, sig2,'RBF_kernel'}, Xs, nb);
    
    RMSE_list(order_index) = sqrt(mean((Ztest-prediction).^2));
    MAE_list(order_index) = mean(abs((Ztest-prediction)));

end 


% Plot order vs RMSE and MAE
figure 
hold on
xlabel('Order')
ylabel('Error')
plot(order_list, RMSE_list,'r.-');
plot(order_list, MAE_list,'b.-');
legend('MSE ','MAE')
grid on 
hold off
fig = gcf;
figname = '../figures/2_2/MSEvsMAE_ordersweep.pdf';
saveas(fig, figname)


order = 50;
    
% Prepare the training data
X = windowize(Z, 1:(order + 1));    
Y = X(:, end);
X = X(:, 1:order);

% Tune hyperparameters 
model = { X , Y , 'f', [], [],'RBF_kernel'};
algorithm = 'simplex';
[gam , sig2, cost] = tunelssvm(model, algorithm, 'crossvalidatelssvm',{10, 'mae'});

[alpha, b] = trainlssvm({X, Y, 'f', gam, sig2,'RBF_kernel'});

% Prep data and make prediction 
Xs = Z(end - order + 1:end , 1);
nb = 50;
prediction = predict({X, Y, 'f', gam, sig2,'RBF_kernel'}, Xs, nb);
    
figure();
hold on;
plot (Ztest , 'k');
plot (prediction , 'r');
hold off;
legend('Test set', 'Prediction')
ylabel('Error') 
xlabel('Test sample') 
grid on 
fig = gcf;
figname = '../figures/2_2/prediction.pdf';
saveas(fig, figname)

% ======================== 2.3 ==========================================

%% Santa Fe dataset
close all 
load santafe.mat

order_list = [5 10 20 30 50 70 100 300 500 800];
n = length(order_list);

gamlist = zeros(1,n);
sig2list = zeros(1,n);

RMSE_list = zeros(1,n);
MAE_list = zeros(1,n);

for order_index = 1:n
    order = order_list(order_index);
    
    % Prepare the training data
    X = windowize(Z, 1:(order + 1));    
    Y = X(:, end);
    X = X(:, 1:order);
    
    % Tune hyperparameters 
    model = { X , Y , 'f', [], [],'RBF_kernel'};
    algorithm = 'simplex';
    [gam , sig2, cost] = tunelssvm(model, algorithm, 'crossvalidatelssvm',{10, 'mse'});
    
    gamlist(order_index) = gam;
    sig2list(order_index) = sig2;
    
    [alpha, b] = trainlssvm({X, Y, 'f', gam, sig2,'RBF_kernel'});
    
    % Prediction 
    Xs = Z(end - order + 1:end , 1);
    nb = 200;
    prediction = predict({X, Y, 'f', gam, sig2,'RBF_kernel'}, Xs, nb);
    
    RMSE_list(order_index) = sqrt(mean((Ztest-prediction).^2));
    MAE_list(order_index) = mean(abs((Ztest-prediction)));

end 

% Plot order vs MSE and MAE
figure 
hold on
xlabel('Order')
ylabel('Error')
plot(order_list, RMSE_list,'r.-');
plot(order_list, MAE_list,'b.-');
legend('MSE ','MAE')
grid on 
hold off
fig = gcf;
figname = '../figures/2_3/MSEvsMAE_ordersweep.pdf';
saveas(fig, figname)


order = 20;
    
% Prepare the training data
X = windowize(Z, 1:(order + 1));    
Y = X(:, end);
X = X(:, 1:order);

% Tune hyperparameters 
model = { X , Y , 'f', [], [],'RBF_kernel'};
algorithm = 'simplex';
[gam , sig2, cost] = tunelssvm(model, algorithm, 'crossvalidatelssvm',{10, 'mae'});

[alpha, b] = trainlssvm({X, Y, 'f', gam, sig2,'RBF_kernel'});

% Prep data and make prediction 
Xs = Z(end - order + 1:end , 1);
nb = 200;
prediction_order_20 = predict({X, Y, 'f', gam, sig2,'RBF_kernel'}, Xs, nb);
    

figure();
hold on;
plot (Ztest , 'k');
plot (prediction_order_20 , 'r');
hold off;
legend('Test set', 'Prediction')
ylabel('Error') 
xlabel('Test sample') 
grid on 
fig = gcf;
figname = '../figures/2_3/prediction_order_20.pdf';
saveas(fig, figname)




